{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "None\n",
      "Data loaded\n",
      "Balanced accuracies per molecule: [0.9993334726337428, 0.9241394889370538, 0.8921204284672583, 0.9981716463516261, 0.9956473829201102, 0.9971436785919647, 0.9990546181853248]\n",
      "Average balanced accuracy: 0.9722301022981544\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "def wavelengthFilter(string):\n",
    "    '''\n",
    "    This function removes the um suffix from the wavelength data.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    string: A string to remove um from.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string: A float\n",
    "    '''\n",
    "    string=string.removesuffix(\" um\")\n",
    "    return float(string)\n",
    "def oneHotEncoding(combination):\n",
    "    '''\n",
    "    This function will turn molecule combinations into a one-hot encoded vector\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    combination: Tuple containing the abundances of the molecules in this order: \"O2\",\"N2\",\"H2\",\"CO2\",\"H2O\",\"CH4\",\"NH3\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vector: One-hot encoded vector of 1's and 0's\n",
    "    '''\n",
    "\n",
    "    #The order of the molecules are: \"O2\",\"N2\",\"H2\",\"CO2\",\"H2O\",\"CH4\",\"NH3\"\n",
    "    vector=[0.]*7\n",
    "    for i,abundance in enumerate(combination):\n",
    "        #At what point should a molecule be considered present? I don't know need to think about that\n",
    "        if abundance>0.001:\n",
    "            vector[i]=1.0\n",
    "    return torch.tensor(vector) \n",
    "def getLabel(filePath,specialMolecules=False):\n",
    "    configFolder=r\"C:\\Users\\Tristan\\Downloads\\HyPCAR3\\configFiles\"\n",
    "    # configFolder=\"/home/tristanb/scratch/configFiles\"\n",
    "    filePath=filePath.removesuffix(\".csv\")\n",
    "    configFilePath=os.path.join(configFolder,filePath)\n",
    "    configFilePath+=\".txt\"\n",
    "\n",
    "    lines=[]\n",
    "    with open(configFilePath) as f:\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "\n",
    "\n",
    "    abundances=lines[54]\n",
    "    abundances=abundances.removeprefix(\"<ATMOSPHERE-LAYER-1>\")\n",
    "    abundances=abundances.split(\",\")\n",
    "    \n",
    "    if not specialMolecules:\n",
    "        abundances=list(map(float,abundances[2:]))#Remove temperature profile information\n",
    "        label=oneHotEncoding(abundances)\n",
    "        return label\n",
    "    else:\n",
    "        abundances=list(map(float,abundances[2:9]))#Only gets target values, not background moolecules or \n",
    "        label=oneHotEncoding(abundances)\n",
    "        return label\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self,samples):#samples contain a listt of all file paths\n",
    "        self.samples=samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        filePath,label=self.samples[index]\n",
    "\n",
    "\n",
    "\n",
    "        #Extract data from file\n",
    "        data=pd.read_csv(filePath)\n",
    "        wavelength=list(map(wavelengthFilter,data.iloc[:,0]))#Removes um from wavelength data\n",
    "        transmittance=list(data.iloc[:,1])\n",
    "        # if len(wavelength)!=784:\n",
    "        #     print(filePath)\n",
    "        # print(len(wavelength))\n",
    "        combinedData=torch.tensor(list(zip(wavelength, transmittance)), dtype=torch.float32)\n",
    "        # if torch.isnan(combinedData).any():\n",
    "        #     print(filePath)\n",
    "        return combinedData,label\n",
    "class detectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels=2, out_channels=128, kernel_size=5, stride=2)\n",
    "        self.bn1=nn.BatchNorm1d(128)\n",
    "        self.pool1=nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2=nn.Conv1d(in_channels=128,out_channels=128,kernel_size=5,stride=2)\n",
    "        self.bn2=nn.BatchNorm1d(128)\n",
    "        self.pool2=nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3=nn.Conv1d(in_channels=128,out_channels=64,kernel_size=3,stride=2)\n",
    "        self.bn3=nn.BatchNorm1d(64)\n",
    "        self.pool3=nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv4=nn.Conv1d(in_channels=64,out_channels=32,kernel_size=2,stride=2)\n",
    "        self.bn4=nn.BatchNorm1d(32)\n",
    "        self.pool4=nn.MaxPool1d(2)\n",
    "\n",
    "        self.dropout1=nn.Dropout(0.4)\n",
    "\n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "        self.fc1=nn.Linear(64,128)\n",
    "        self.dropout2=nn.Dropout(0.75)\n",
    "        self.fc2=nn.Linear(128,64)\n",
    "        self.fc3=nn.Linear(64,7)#7 molecule present\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Permute dimensions to [batch_size, channels, sequence_length]\n",
    "        x=x.permute(0, 2, 1)\n",
    "        x=F.relu(self.bn1(self.conv1(x)))\n",
    "        x=self.pool1(x)\n",
    "\n",
    "        x=F.relu(self.bn2(self.conv2(x)))\n",
    "        x=self.pool2(x)\n",
    "\n",
    "        x=F.relu(self.bn3(self.conv3(x)))\n",
    "        x=self.pool3(x)\n",
    "\n",
    "        x=F.relu(self.bn4(self.conv4(x)))\n",
    "        x=self.pool4(x)\n",
    "\n",
    "        x=self.dropout1(x)\n",
    "\n",
    "        x=torch.flatten(x, 1)\n",
    "\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.dropout2(x)\n",
    "        \n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "testingData=[]\n",
    "\n",
    "\n",
    "allSamples=[]\n",
    "allLabels=[]\n",
    "#\n",
    "\n",
    "testSplit=0.15\n",
    "for atmosphereType in [\"A\",\"B\",\"C\",\"None\"]:\n",
    "    print(atmosphereType)\n",
    "    curFolderPath=r\"C:\\Users\\Tristan\\Downloads\\HyPCAR3\\data\"\n",
    "    curFolderPath+=\"\\\\\"+atmosphereType\n",
    "    files=[]\n",
    "    for path in os.listdir(curFolderPath):\n",
    "\n",
    "        if atmosphereType==\"None\":\n",
    "            #Gett labels in a special way\n",
    "            label=getLabel(path,True)\n",
    "        else:\n",
    "\n",
    "            label=getLabel(path)\n",
    "        files.append((os.path.join(curFolderPath,path),label))\n",
    "        \n",
    "\n",
    "    random.shuffle(files)\n",
    "\n",
    "    testingSamples=[]\n",
    "    for i,data in enumerate(files):\n",
    "        path,label=data[0],data[1]\n",
    "        if i<(len(files)*testSplit):#Adds testing data\n",
    "            testingSamples.append((path,label))\n",
    "        else:\n",
    "            break\n",
    "            #Don't need more\n",
    "    testingData.extend(testingSamples)\n",
    "\n",
    "print(\"Data loaded\")\n",
    "\n",
    "\n",
    "random.shuffle(testingData)\n",
    "testingDataset=customDataset(testingData)\n",
    "testingDataloader=DataLoader(testingDataset,batch_size=32,shuffle=True)#Testing data loader\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "detect=detectionModel()\n",
    "detect=detect.to(device)\n",
    "detect.load_state_dict(torch.load(r\"C:\\Users\\Tristan\\Downloads\\HyPCAR3\\detectionModel.pt\",weights_only=True))\n",
    "\n",
    "allPred=[]\n",
    "allLabel=[]\n",
    "for batch in testingDataloader:\n",
    "    data,labels=batch\n",
    "    data,labels=data.to(device),labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs=detect(data)\n",
    "    preds = (outputs > 0.5)\n",
    "    preds=preds.to(device)\n",
    "    allLabel.append(labels)\n",
    "    allPred.append(preds)\n",
    "\n",
    "allLabel=np.concatenate([a.cpu().numpy() if hasattr(a, \"cpu\") else a for a in allLabel],axis=0)\n",
    "allPred=np.concatenate([a.cpu().numpy() if hasattr(a, \"cpu\") else a for a in allPred],axis=0)\n",
    "\n",
    "\n",
    "numMolecules=allLabel.shape[1]\n",
    "balancedAcc=[]\n",
    "\n",
    "for i in range(numMolecules):\n",
    "    ba=balanced_accuracy_score(allLabel[:, i], allPred[:, i])\n",
    "    balancedAcc.append(ba)\n",
    "\n",
    "avgBalancedAcc=np.mean(balancedAcc)\n",
    "\n",
    "print(\"Balanced accuracies per molecule:\", balancedAcc)\n",
    "print(\"Average balanced accuracy:\", avgBalancedAcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O2', 'N2', 'H2', 'CO2', 'H2O', 'CH4', 'NH3']\n",
      "[0.0, 0.3819293813457363, 0.0, 0.0, 0.33511101651338593, 0.2576119023030262, 0.0253476998378517]\n",
      "C:\\Users\\Tristan\\Downloads\\HyPCAR3\\data\\A\\A2_9933.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def getAbundances(fileName):\n",
    "    '''\n",
    "    This function grabs the molecule abundances from the config files and returns them as a vector\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    fileName: The name of the config file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    abundances: A vector containing the abundance information\n",
    "    '''\n",
    "    abundances=[0.0]*7\n",
    "    moleculeNames=[\"O2\", \"N2\", \"CO2\", \"H2O\", \"N2O\", \"CH4\", \"H2S\"]\n",
    "    lines=[]\n",
    "    with open(fileName) as f:\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "\n",
    "    abundances=lines[54]\n",
    "    abundances=abundances.removeprefix(\"<ATMOSPHERE-LAYER-1>\")\n",
    "    abundances=abundances.split(\",\")\n",
    "\n",
    "    if \"None\" in os.path.basename(fileName):\n",
    "        #Special case\n",
    "        abundances=list(map(float,abundances[2:9]))#Only gets target values, not background moolecules or \n",
    "\n",
    "    else:\n",
    "        abundances=list(map(float,abundances[2:]))#Remove temperature profile information\n",
    "    return abundances\n",
    "\n",
    "configs=[file for file in os.listdir(r\"C:\\Users\\Tristan\\Downloads\\HyPCAR3\\configFiles\")]\n",
    "\n",
    "sample=random.sample(configs,1)\n",
    "dataFolder=r\"C:\\Users\\Tristan\\Downloads\\HyPCAR3\\data\"\n",
    "configFolder=r\"C:\\Users\\Tristan\\Downloads\\HyPCAR3\\configFiles\"\n",
    "for file in sample:\n",
    "    baseName=os.path.basename(file)\n",
    "    baseName=baseName.removesuffix(\".txt\")\n",
    "    baseName+=\".csv\"\n",
    "    folder=baseName.split(\"_\")[0]\n",
    "    if len(folder)==2:\n",
    "        folder=\"A\"\n",
    "    elif len(folder)>1:\n",
    "        folder=\"None\"\n",
    "\n",
    "    newPath=dataFolder+f\"\\\\{folder}\"\n",
    "    newPath+=f\"\\\\{baseName}\"\n",
    "    data=pd.read_csv(newPath)\n",
    "    w,t=list(data.iloc[0:,0]),list(data.iloc[0:,1])\n",
    "  \n",
    "    with open(\"tempTransmittance.csv\",\"w\") as f:\n",
    "        for i in range(len(w)):\n",
    "            f.write(str(w[i][:-3])+\",\"+str(t[i])+\"\\n\")\n",
    "    \n",
    "    print([\"O2\",\"N2\",\"H2\",\"CO2\",\"H2O\",\"CH4\",\"NH3\"])\n",
    "    print(getAbundances(os.path.join(configFolder,file)))\n",
    "    print(newPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence:\n",
      "  Normal Model:     1.6513\n",
      "  Fine-tuned Model: 0.5565\n",
      "\n",
      "Cross Entropy:\n",
      "  Normal Model:     2.1916\n",
      "  Fine-tuned Model: 1.0967\n",
      "\n",
      "Mean Squared Error (MSE):\n",
      "  Normal Model:     982.6050\n",
      "  Fine-tuned Model: 436.3768\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data in percentages from the table\n",
    "molecules = [\"O2\", \"N2\", \"CO2\", \"H2O\", \"N2O\", \"CH4\", \"H2S\"]\n",
    "\n",
    "# True values (using 0 for H2S as \"Not Present\")\n",
    "true = np.array([20.9, 78.1, 0.03795, 0.35004, 0.000032, 0.00017, 0.0])\n",
    "\n",
    "# Predictions from the normal model\n",
    "normal = np.array([54.74, 7.28, 4.65, 26.18, 4.97, 0.08, 2.11])\n",
    "\n",
    "# Predictions from the fine-tuned model\n",
    "fine_tuned = np.array([38.7, 33.65, 27.64, 0.00097, 0.0096, 0.00019, 0.0032])\n",
    "\n",
    "# Normalize distributions so that they sum to 1; note that the predicted values\n",
    "# for both models already sum approximately to 100, but we do it explicitly.\n",
    "p_true = true / true.sum()\n",
    "p_normal = normal / normal.sum()\n",
    "p_finetuned = fine_tuned / fine_tuned.sum()\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Computes KL divergence:  KL(p||q) = sum_i p[i] * log(p[i]/q[i])\n",
    "    We add a small epsilon to avoid division or log of zero errors.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12\n",
    "    p_safe = np.maximum(p, epsilon)\n",
    "    q_safe = np.maximum(q, epsilon)\n",
    "    return np.sum(p_safe * np.log(p_safe / q_safe))\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "    \"\"\"\n",
    "    Computes the cross entropy H(p,q) = -sum_i p[i] * log(q[i]).\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12\n",
    "    q_safe = np.maximum(q, epsilon)\n",
    "    return -np.sum(p * np.log(q_safe))\n",
    "\n",
    "def mse(pred, true):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error between prediction and true values.\n",
    "    \"\"\"\n",
    "    return np.mean((pred - true)**2)\n",
    "\n",
    "# Compute KL divergence for both models (using the true distribution as p)\n",
    "kl_normal = kl_divergence(p_true, p_normal)\n",
    "kl_finetuned = kl_divergence(p_true, p_finetuned)\n",
    "\n",
    "# Compute cross entropy for both models\n",
    "ce_normal = cross_entropy(p_true, p_normal)\n",
    "ce_finetuned = cross_entropy(p_true, p_finetuned)\n",
    "\n",
    "# Compute MSE for both models using the raw percentages\n",
    "mse_normal = mse(normal, true)\n",
    "mse_finetuned = mse(fine_tuned, true)\n",
    "\n",
    "print(\"KL Divergence:\")\n",
    "print(f\"  Normal Model:     {kl_normal:.4f}\")\n",
    "print(f\"  Fine-tuned Model: {kl_finetuned:.4f}\\n\")\n",
    "\n",
    "print(\"Cross Entropy:\")\n",
    "print(f\"  Normal Model:     {ce_normal:.4f}\")\n",
    "print(f\"  Fine-tuned Model: {ce_finetuned:.4f}\\n\")\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\")\n",
    "print(f\"  Normal Model:     {mse_normal:.4f}\")\n",
    "print(f\"  Fine-tuned Model: {mse_finetuned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence:\n",
      "  Normal Model:     1.6120\n",
      "  Fine-tuned Model: 1.5349\n",
      "\n",
      "Cross Entropy:\n",
      "  Normal Model:     2.1522\n",
      "  Fine-tuned Model: 2.0752\n",
      "\n",
      "Mean Squared Error (MSE):\n",
      "  Normal Model:     979.5950\n",
      "  Fine-tuned Model: 932.0830\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data in percentages from the table\n",
    "molecules = [\"O2\", \"N2\", \"CO2\", \"H2O\", \"N2O\", \"CH4\", \"H2S\"]\n",
    "\n",
    "# True values (using 0 for H2S as \"Not Present\")\n",
    "true = np.array([20.9, 78.1, 0.03795, 0.35004, 0.000032, 0.00017, 0.0])\n",
    "\n",
    "# Predictions from the normal model\n",
    "normal = np.array([57.269322872161865, 7.579978555440903, 20.22359073162079, 12.640121579170227, 1.5301313251256943, 0.039025183650664985, 0.717834709212184])\n",
    "\n",
    "# Predictions from the fine-tuned model\n",
    "fine_tuned = np.array([52.26215124130249, 8.5650734603405, 22.9727640748024, 13.6198952794075, 01.8039532005786896, 0.04164810525253415, 0.7345139980316162])\n",
    "\n",
    "# Normalize distributions so that they sum to 1; note that the predicted values\n",
    "# for both models already sum approximately to 100, but we do it explicitly.\n",
    "p_true = true / true.sum()\n",
    "p_normal = normal / normal.sum()\n",
    "p_finetuned = fine_tuned / fine_tuned.sum()\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Computes KL divergence:  KL(p||q) = sum_i p[i] * log(p[i]/q[i])\n",
    "    We add a small epsilon to avoid division or log of zero errors.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12\n",
    "    p_safe = np.maximum(p, epsilon)\n",
    "    q_safe = np.maximum(q, epsilon)\n",
    "    return np.sum(p_safe * np.log(p_safe / q_safe))\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "    \"\"\"\n",
    "    Computes the cross entropy H(p,q) = -sum_i p[i] * log(q[i]).\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12\n",
    "    q_safe = np.maximum(q, epsilon)\n",
    "    return -np.sum(p * np.log(q_safe))\n",
    "\n",
    "def mse(pred, true):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error between prediction and true values.\n",
    "    \"\"\"\n",
    "    return np.mean((pred - true)**2)\n",
    "\n",
    "# Compute KL divergence for both models (using the true distribution as p)\n",
    "kl_normal = kl_divergence(p_true, p_normal)\n",
    "kl_finetuned = kl_divergence(p_true, p_finetuned)\n",
    "\n",
    "# Compute cross entropy for both models\n",
    "ce_normal = cross_entropy(p_true, p_normal)\n",
    "ce_finetuned = cross_entropy(p_true, p_finetuned)\n",
    "\n",
    "# Compute MSE for both models using the raw percentages\n",
    "mse_normal = mse(normal, true)\n",
    "mse_finetuned = mse(fine_tuned, true)\n",
    "\n",
    "print(\"KL Divergence:\")\n",
    "print(f\"  Normal Model:     {kl_normal:.4f}\")\n",
    "print(f\"  Fine-tuned Model: {kl_finetuned:.4f}\\n\")\n",
    "\n",
    "print(\"Cross Entropy:\")\n",
    "print(f\"  Normal Model:     {ce_normal:.4f}\")\n",
    "print(f\"  Fine-tuned Model: {ce_finetuned:.4f}\\n\")\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\")\n",
    "print(f\"  Normal Model:     {mse_normal:.4f}\")\n",
    "print(f\"  Fine-tuned Model: {mse_finetuned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.269322872161865, 7.579978555440903, 20.22359073162079, 12.640121579170227, 1.5301313251256943, 0.039025183650664985, 0.717834709212184]\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for val in [0.5726932287216187, 0.07579978555440903, 0.20223590731620789, 0.12640121579170227, 0.015301313251256943, 0.00039025183650664985, 0.0071783470921218395]:\n",
    "    temp.append(val*100)\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
